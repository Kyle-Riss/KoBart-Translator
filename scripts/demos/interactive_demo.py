"""
í•™ìŠµëœ Multi-Task KoBART ëŒ€í™”í˜• ë°ëª¨
"""

import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

import torch
from kobart_translator import MultiTaskKoBART
from transformers import PreTrainedTokenizerFast


class InteractiveDemo:
    """ëŒ€í™”í˜• ë°ëª¨ í´ë˜ìŠ¤"""
    
    def __init__(self, checkpoint_path: str):
        """ì´ˆê¸°í™”"""
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        print("="*60)
        print("Multi-Task KoBART ëŒ€í™”í˜• ë°ëª¨")
        print("="*60)
        print()
        
        # í† í¬ë‚˜ì´ì € ë¡œë“œ
        print("í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...")
        self.tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-base-v1')
        print("âœ“ í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ")
        
        # ëª¨ë¸ ë¡œë“œ
        print("\ní•™ìŠµëœ ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model = MultiTaskKoBART()
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        print("âœ“ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # íƒœìŠ¤í¬ ì •ë³´
        self.tasks = {
            '1': ('style_transfer', 'ìŠ¤íƒ€ì¼ ë³€í™˜ (êµ¬ì–´ì²´ â†’ ê²©ì‹ì²´)'),
            '2': ('dialogue_summarization', 'ëŒ€í™” ìš”ì•½'),
            '3': ('role_generation', 'ì—­í•  ê¸°ë°˜ ì‘ë‹µ ìƒì„±'),
            '4': ('qa_generation', 'QA ë‹µë³€ ìƒì„±')
        }
        
        print(f"\në””ë°”ì´ìŠ¤: {self.device}")
        print("ì¤€ë¹„ ì™„ë£Œ!\n")
    
    def show_menu(self):
        """ë©”ë‰´ í‘œì‹œ"""
        print("\n" + "="*60)
        print("íƒœìŠ¤í¬ ì„ íƒ:")
        print("-"*60)
        for key, (task_id, description) in self.tasks.items():
            print(f"  {key}. {description}")
        print("  0. ì¢…ë£Œ")
        print("="*60)
    
    def generate(self, text: str, task: str) -> str:
        """í…ìŠ¤íŠ¸ ìƒì„±"""
        with torch.no_grad():
            # í† í°í™”
            inputs = self.tokenizer(
                text,
                return_tensors="pt",
                max_length=512,
                truncation=True
            )
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ìƒì„±
            outputs = self.model.generate(
                input_ids=inputs['input_ids'],
                attention_mask=inputs['attention_mask'],
                task=task,
                max_length=100
            )
            
            # ë””ì½”ë”©
            result = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            return result
    
    def run(self):
        """ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰"""
        print("ëŒ€í™”í˜• ëª¨ë“œ ì‹œì‘!")
        print("(ê° íƒœìŠ¤í¬ë¥¼ ì„ íƒí•˜ê³  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”)\n")
        
        while True:
            self.show_menu()
            
            choice = input("\níƒœìŠ¤í¬ ë²ˆí˜¸ ì…ë ¥: ").strip()
            
            if choice == '0':
                print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
                break
            
            if choice not in self.tasks:
                print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ì£¼ì„¸ìš”.")
                continue
            
            task_id, task_name = self.tasks[choice]
            print(f"\nì„ íƒëœ íƒœìŠ¤í¬: {task_name}")
            print("-"*60)
            
            # íƒœìŠ¤í¬ë³„ ì…ë ¥ ì˜ˆì‹œ
            examples = {
                'style_transfer': 'ì˜ˆ: "ì´ê±° ì¢€ ë„ì™€ì£¼ì„¸ìš”"',
                'dialogue_summarization': 'ì˜ˆ: "A: íšŒì˜ ëª‡ì‹œ? B: 2ì‹œìš”"',
                'role_generation': 'ì˜ˆ: "[ì„ ìƒë‹˜] íŒŒì´ì¬ì´ë€?"',
                'qa_generation': 'ì˜ˆ: "ì§ˆë¬¸: ì„œìš¸ ì¸êµ¬ëŠ”?"'
            }
            
            print(f"ì…ë ¥ í˜•ì‹: {examples[task_id]}")
            user_input = input("\nì…ë ¥: ").strip()
            
            if not user_input:
                print("âš ï¸ ì…ë ¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                continue
            
            print("\nìƒì„± ì¤‘...", end='', flush=True)
            
            try:
                result = self.generate(user_input, task_id)
                print("\r" + " "*20)  # ì§€ìš°ê¸°
                print(f"ì¶œë ¥: {result}")
                
            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            
            print("\n" + "-"*60)
            input("Enter í‚¤ë¥¼ ëˆŒëŸ¬ ê³„ì†...")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    checkpoint_path = "/Users/arka/Desktop/Ko-bart/multi_task_model.pt"
    
    try:
        demo = InteractiveDemo(checkpoint_path)
        demo.run()
        
    except FileNotFoundError:
        print("âŒ í•™ìŠµëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € train_multi_task.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
        print("\nì‹¤í–‰ ë°©ë²•:")
        print("  python3 train_multi_task.py")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    main()


