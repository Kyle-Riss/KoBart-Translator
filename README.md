# KoBART Multi-Task Learning Project

KoBARTëŠ” í•œêµ­ì–´ì— íŠ¹í™”ëœ BART (Bidirectional and Auto-Regressive Transformers) ëª¨ë¸ì…ë‹ˆë‹¤.

ì´ í”„ë¡œì íŠ¸ëŠ” **í•˜ë‚˜ì˜ ê³µìœ  ì¸ì½”ë”**ì™€ **4ê°œì˜ íƒœìŠ¤í¬ë³„ ë””ì½”ë” í—¤ë“œ**ë¥¼ ê°€ì§„ ë©€í‹°íƒœìŠ¤í¬ í•™ìŠµ ì•„í‚¤í…ì²˜ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

## ğŸ¯ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
ì…ë ¥ â†’ Shared Encoder â†’ 4ê°œì˜ Decoder Heads
                         â”œâ”€â”€ Style Transfer
                         â”œâ”€â”€ Dialogue Summarization  
                         â”œâ”€â”€ Role-based Generation
                         â””â”€â”€ QA Answer Generation
```

## ì„¤ì¹˜ ë°©ë²•

### 1. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

ë˜ëŠ” ê°œë³„ ì„¤ì¹˜:

```bash
pip install torch transformers sentencepiece
```

## ì‚¬ìš© ë°©ë²•

### 1. ê¸°ë³¸ KoBART ëª¨ë¸

#### ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ ë° í…ŒìŠ¤íŠ¸

```bash
python3 quick_start.py        # ë¹ ë¥¸ ì‹œì‘
python3 example_simple.py     # ìƒì„¸ ì˜ˆì œ
python3 verify_installation.py # ì„¤ì¹˜ ê²€ì¦
```

### 2. Multi-Task KoBART ëª¨ë¸

#### ëª¨ë¸ í…ŒìŠ¤íŠ¸

```bash
python3 multi_task_kobart.py
```

#### í•™ìŠµ ì‹œì‘

```bash
python3 train_multi_task.py
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
- ê³µìœ  ì¸ì½”ë” ë¡œë“œ
- 4ê°œì˜ íƒœìŠ¤í¬ë³„ ë””ì½”ë” ìƒì„±
- ìƒ˜í”Œ ë°ì´í„°ë¡œ í•™ìŠµ

### Python ì½”ë“œì—ì„œ ì§ì ‘ ì‚¬ìš©

```python
from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast

# ëª¨ë¸ ë¡œë“œ
tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-base-v1')
model = BartForConditionalGeneration.from_pretrained('gogamza/kobart-base-v1')

# í…ìŠ¤íŠ¸ ìƒì„±
text = "KoBARTëŠ” í•œêµ­ì–´ì— íŠ¹í™”ëœ BART ëª¨ë¸ì…ë‹ˆë‹¤."
inputs = tokenizer(text, return_tensors="pt")
output_ids = model.generate(inputs['input_ids'], max_length=50)
output = tokenizer.decode(output_ids[0], skip_special_tokens=True)

print(output)
```

## ì£¼ìš” ê¸°ëŠ¥

### ê¸°ë³¸ KoBART
- **ìš”ì•½ ìƒì„±**: ê¸´ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½
- **í…ìŠ¤íŠ¸ ìƒì„±**: ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¡œë¶€í„° í…ìŠ¤íŠ¸ ìƒì„±
- **ë¬¸ì¥ ë³€í™˜**: ë¬¸ì¥ì„ ë‹¤ë¥¸ í˜•íƒœë¡œ ë³€í™˜

### Multi-Task KoBART (4ê°œì˜ ì „ë¬¸ ë””ì½”ë”)
1. **Style Transfer**: êµ¬ì–´ì²´ â†” ê²©ì‹ì²´ ë³€í™˜
2. **Dialogue Summarization**: ëŒ€í™” ë‚´ìš© ìš”ì•½
3. **Role-conditioned Generation**: ì—­í•  ê¸°ë°˜ ì‘ë‹µ ìƒì„± (ì„ ìƒë‹˜, ì¹œêµ¬ ë“±)
4. **QA Answer Generation**: ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±

## ëª¨ë¸ ì •ë³´

- **ëª¨ë¸ëª…**: gogamza/kobart-base-v1
- **ê¸°ë°˜**: BART (Facebook AI)
- **ì–¸ì–´**: í•œêµ­ì–´
- **íƒœìŠ¤í¬**: ìš”ì•½, ìƒì„±, ë³€í™˜ ë“±

## ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- Python 3.8 ì´ìƒ
- PyTorch 2.0 ì´ìƒ
- ìµœì†Œ 8GB RAM ê¶Œì¥
- GPU ì‚¬ìš© ì‹œ ë” ë¹ ë¥¸ ì²˜ë¦¬ ê°€ëŠ¥ (ì„ íƒì‚¬í•­)

## ğŸ“š ë¬¸ì„œ

- **MULTI_TASK_GUIDE.md**: ë©€í‹°íƒœìŠ¤í¬ ì‚¬ìš© ê°€ì´ë“œ
- **ARCHITECTURE.md**: ì•„í‚¤í…ì²˜ ìƒì„¸ ì„¤ëª…
- **USAGE_GUIDE.md**: ê¸°ë³¸ ì‚¬ìš©ë²•
- **ì‹œì‘í•˜ê¸°.md**: ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ (í•œê¸€)

## ğŸ“Š ëª¨ë¸ ì •ë³´

### ê¸°ë³¸ KoBART
- íŒŒë¼ë¯¸í„°: ~124M

### Multi-Task KoBART
- ê³µìœ  ì¸ì½”ë”: ~66M íŒŒë¼ë¯¸í„°
- 4ê°œ ë””ì½”ë”: ê° ~103M íŒŒë¼ë¯¸í„°
- ì´ íŒŒë¼ë¯¸í„°: ~481M

## ì°¸ê³  ìë£Œ

- [Hugging Face Model Hub](https://huggingface.co/gogamza/kobart-base-v1)
- [BART ë…¼ë¬¸](https://arxiv.org/abs/1910.13461)


